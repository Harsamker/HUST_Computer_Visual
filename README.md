# 华中科技大学2023年下半年计算机视觉

## 上机实验

上机实验一：基于前馈神经网络的分类任务设计

上机实验二：基于卷积神经网络的MNIST手写体数字识别

上机实验三：基于卷积神经网络的两位数字比较

上机实验四：卷积神经网络可解释性分析

***实验4中预测猫狗的二分类模型（model = torch.load('torch_alex.pth')里面torch-alex.pth）太大辣，开不了Git LFS，上传不了，找老师要！！！***

## 结课报告、专题实验报告要求

卷积神经网络在进行图像分类任务时的可解释性分析是一个重要研究课题。经典的可解释性方法有LIME, RISE, Grad-CAM, Grad-CAM++, ScoreCAM, LayerCAM等。请阅读上述CNN可解释性方法所对应的原始论文，并要求：

1. 简述每种可解释性方法的基本原理，并对各类可解释性方法进行分析、比较；
2. 复现（也可运行开源）LIME代码，得到可解释性分析结果；
3. 复现（也可运行开源）Grad-CAM++代码，得到可解释性分析结果；
4. 复现（也可运行开源）ScoreCAM代码，得到可解释性分析结果；
5. 对比三种方法的可解释性分析结果，分析各自的优缺点；
6. 报告正文宋体小四，行间距1.5倍。一级标题四号黑体加粗，二级标题小四黑体加粗，三级标题小四宋体加粗。报告字数不做限制，将以上几点介绍清楚即可，鼓励在报告中展现自己对每种方法的理解或对方法存在的缺陷的思考、改进等。
